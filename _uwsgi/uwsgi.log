...gracefully killing workers...
Gracefully killing worker 1 (pid: 462731)...
worker 1 buried after 2 seconds
binary reloading uWSGI...
chdir() to /data/cty/sandbox_service/_uwsgi
closing all non-uwsgi socket fds > 2 (max_fd = 1048576)...
found fd 3 mapped to socket 0 (0.0.0.0:8760)
running /data/anaconda3/envs/program_synthesis/bin/uwsgi
[uWSGI] getting INI configuration from uconfig.ini
*** Starting uWSGI 2.0.21 (64bit) on [Mon Jul 24 15:40:37 2023] ***
compiled with version: 11.2.0 on 10 March 2023 16:42:24
os: Linux-5.15.0-76-generic #83~20.04.1-Ubuntu SMP Wed Jun 21 20:23:31 UTC 2023
nodename: 01
machine: x86_64
clock source: unix
pcre jit disabled
detected number of CPU cores: 24
current working directory: /data/cty/sandbox_service/_uwsgi
detected binary path: /data/anaconda3/envs/program_synthesis/bin/uwsgi
your processes number limit is 1029858
your memory page size is 4096 bytes
detected max file descriptor number: 1048576
lock engine: pthread robust mutexes
thunder lock: disabled (you can enable it with --thunder-lock)
uwsgi socket 0 inherited INET address 0.0.0.0:8760 fd 3
Python version: 3.9.16 (main, Mar  8 2023, 14:00:05)  [GCC 11.2.0]
Set PythonHome to /data/anaconda3/envs/program_synthesis
*** Python threads support is disabled. You can enable it with --enable-threads ***
Python main interpreter initialized at 0x27e5f70
your server socket listen backlog is limited to 100 connections
your mercy for graceful operations on workers is 60 seconds
mapped 219568 bytes (214 KB) for 1 cores
*** Operational MODE: single process ***
added /data/cty/sandbox_service/ to pythonpath.
WSGI app 0 (mountpoint='') ready in 2 seconds on interpreter 0x27e5f70 pid: 136374 (default app)
mountpoint  already configured. skip.
*** uWSGI is running in multiple interpreter mode ***
gracefully (RE)spawned uWSGI master process (pid: 136374)
spawned uWSGI worker 1 (pid: 462838, cores: 1)
*** Stats server enabled on /data/cty/sandbox_service/_uwsgi/uwsgi.status fd: 9 ***
Loading /data/cty/sandbox_service/web_vision/models/weights/yolov8n.engine for TensorRT inference...
[07/24/2023-15:40:44] [TRT] [I] [MemUsageChange] Init CUDA: CPU +330, GPU +0, now: CPU 414, GPU 455 (MiB)
[07/24/2023-15:40:44] [TRT] [I] Loaded engine size: 15 MiB
[07/24/2023-15:40:45] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +876, GPU +392, now: CPU 1336, GPU 863 (MiB)
[07/24/2023-15:40:45] [TRT] [W] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
[07/24/2023-15:40:45] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)
[07/24/2023-15:40:45] [TRT] [I] [MemUsageChange] Init cuDNN: CPU +0, GPU +34, now: CPU 1320, GPU 863 (MiB)
[07/24/2023-15:40:45] [TRT] [W] TensorRT was linked against cuDNN 8.4.1 but loaded cuDNN 8.3.2
[07/24/2023-15:40:45] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 0 (MiB)

0: 640x640 1 traffic light, 1.8ms
Speed: 12.0ms preprocess, 1.8ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)
[pid: 462838|app: 0|req: 1/1] 127.0.0.1 () {46 vars in 734 bytes} [Mon Jul 24 15:40:43 2023] POST /vision/detect_traffic_light_color => generated 67 bytes in 5545 msecs (HTTP/1.1 200) 2 headers in 71 bytes (1 switches on core 0)
